{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'bank-additional-full.csv' does not exist: b'bank-additional-full.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-48f667ab3115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mkolumny_numeryczne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Duration'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Pdays'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'emp_var_rate'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cons_price_idx'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cons_conf_idx'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'euribor3m'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'nr_employed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Campaign'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Previous'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bank-additional-full.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkolumny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# sprawdzamy czy są braki danych\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'bank-additional-full.csv' does not exist: b'bank-additional-full.csv'"
     ]
    }
   ],
   "source": [
    "kolumny = ['Age', 'Job', 'Marital', 'Education', 'Default', \\\n",
    "           'Housing', 'Personal_loan', 'Contact', 'Month','Day_of_week', 'Duration', \\\n",
    "           'Campaign', 'Pdays', 'Previous', 'Poutcome','emp_var_rate','cons_price_idx','cons_conf_idx','euribor3m','nr_employed', 'Target']\n",
    "\n",
    "kolumny_kategoryczne = ['Job','Marital','Education','Default','Housing','Personal_loan','Contact','Month','Day_of_week','Poutcome']\n",
    "kolumny_numeryczne = ['Age','Duration','Pdays','emp_var_rate','cons_price_idx','cons_conf_idx','euribor3m','nr_employed','Campaign','Previous']\n",
    "\n",
    "data = pd.read_csv('bank-additional-full.csv', sep=';', names=kolumny, header=1)\n",
    "\n",
    "# sprawdzamy czy są braki danych\n",
    "data.isnull().any()\n",
    "data[data[:]=='unknown'].count()\n",
    "\n",
    "Y = pd.DataFrame()\n",
    "X = pd.DataFrame()\n",
    "Y['Target'] = data['Target']\n",
    "print(Y)\n",
    "X = data.drop(['Target'], 1)\n",
    "print(X)\n",
    "\n",
    "# Check target values balance\n",
    "print(f\"Target value counts \\n{Y['Target'].value_counts()}\")\n",
    "yes = len(Y[Y['Target'] == 'yes'])/ len(Y)\n",
    "print(f\"Percentage of 'yes' answer: {yes}\")\n",
    "print(f\"Percentage of 'no' answer: {1-yes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Box ploty dla numerycznych\n",
    "\n",
    "# for col in kolumny_numeryczne:\n",
    "#     plt.boxplot(data[col])\n",
    "#     plt.title(\"Boxplot dla \"+col)\n",
    "#     plt.savefig('box_ploty/' + col + \"_box.png\")\n",
    "#     plt.show()\n",
    "for col in kolumny_numeryczne:\n",
    "    sns.boxplot(data[col], whis=1.5)\n",
    "    plt.title(\"Boxplot dla \"+col)\n",
    "    plt.savefig('box_ploty/' + col + \"_box.png\")\n",
    "    plt.show()\n",
    "\n",
    "# zliczanie pustych komórek dla poszczegolnych kolumn\n",
    "for col in kolumny_kategoryczne:\n",
    "    count = data[data[col]=='unknown'][col].count()\n",
    "    print(f'Kolumna: {col}, Liczba nieznanych: ', count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers mapping 0 - no, 1 - yes\n",
    "answer_mapping = {\"no\": 0, \"yes\": 1}\n",
    "\n",
    "data['Target'] = data['Target'].map(answer_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping Marital\n",
    "print(data['Marital'].value_counts())\n",
    "\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['Marital'])], axis=1)\n",
    "\n",
    "\n",
    "data.rename(columns={'unknown': 'Marital_unk'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wiek\n",
    "data['Age'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cons_conf_idx\n",
    "data.cons_conf_idx.value_counts()\n",
    "print(data['cons_conf_idx'].quantile(0.75)+1.5*(data['cons_conf_idx'].quantile(0.75)-data['cons_conf_idx'].quantile(0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edukacja\n",
    "print(data['Education'].value_counts())\n",
    "# Czy podstawowa edukacja\n",
    "\n",
    "data['if_basic_educ'] = 0\n",
    "data.loc[data['Education'].isin(['basic.4y','basic.6y','basic.9y']),'if_basic_educ'] = 1\n",
    "\n",
    "\n",
    "print(data['if_basic_educ'].value_counts())\n",
    "\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['Education'])], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default - problemy z kredytem\n",
    "print(data['Default'].value_counts())\n",
    "\n",
    "data['if_no_default'] = 0\n",
    "data.loc[data['Default']=='no', 'if_no_default'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housing - kredyt mieszkaniowy\n",
    "housing_mapping = {'no': 0, 'yes':1, 'unknown': np.nan}\n",
    "\n",
    "data['Housing'] = data['Housing'].map(housing_mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal loan - pozyczka\n",
    "personal_loan_mapping = {'no': 0, 'yes':1, 'unknown':np.nan}\n",
    "\n",
    "data['Personal_loan'] = data['Personal_loan'].map(personal_loan_mapping)\n",
    "\n",
    "# If_no_loan - jesli nie ma kredytu\n",
    "\n",
    "data['if_no_loan'] = 0\n",
    "data.loc[(data['Housing']==0) & (data['Personal_loan']==0),'if_no_loan']=1\n",
    "print(data['if_no_loan'].value_counts())\n",
    "\n",
    "\n",
    "# if_both_loan - jesli ma obydwa kredyty (housing i personal)\n",
    "\n",
    "data['if_both_loan'] = 0\n",
    "data.loc[(data['Housing']==1) & (data['Personal_loan']==1),'if_both_loan']=1\n",
    "print(data['if_both_loan'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Contact - Kontakt\n",
    "contact_mapping = {'telephone': 0, 'cellular':1}\n",
    "\n",
    "data['Contact'] = data['Contact'].map(contact_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zawody na binarne\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['Job'])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miesiące na binarne\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['Month'])], axis=1)\n",
    "\n",
    "# Kwartały\n",
    "\n",
    "data['quartile']=0\n",
    "data.loc[data['Month'].isin(['jan','feb','mar']), \"quartile\"] = 'qr_1',\n",
    "data.loc[data['Month'].isin(['apr','may','jun']), \"quartile\"] = 'qr_2',\n",
    "data.loc[data['Month'].isin(['jul','aug','sep']), \"quartile\"] = 'qr_3',\n",
    "data.loc[data['Month'].isin(['oct','nov','dec']), \"quartile\"] = 'qr_4'\n",
    "print(data['quartile'].value_counts())\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['quartile'])], axis=1)\n",
    "# Wakacje\n",
    "\n",
    "data['if_holidays'] = 0\n",
    "data.loc[data['Month'].isin(['jul','aug']),'if_holidays']=1\n",
    "print(data['if_holidays'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dzien tygodnia\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['Day_of_week'])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jeśli był kontaktowany w tej kampanii\n",
    "\n",
    "data['if_contact_this_camp'] = 0\n",
    "data.loc[data['Campaign']>1,'if_contact_this_camp'] = 1\n",
    "print(data['if_contact_this_camp'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outliers dla kampanii\n",
    "data['Campaign'].quantile(0.95)\n",
    "data.loc[data['Campaign']>7, 'Target'].value_counts()\n",
    "data.loc[data['Campaign']>7,'Campaign'] = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jesli byl kiedykolwiek kontaktowany podczas poprzedniej kampanii\n",
    "\n",
    "data['if_contact_prev'] = 0\n",
    "data.loc[data['Pdays'] != 999, 'if_contact_prev'] = 1\n",
    "print(data['if_contact_prev'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jesli byl kontaktowany poza aktualna i poprzednia kamapania\n",
    "data.loc[(data['if_contact_prev']==0) & (data['Previous']>0),'Previous'].value_counts()\n",
    "data['if_contact_no_camp'] = 0\n",
    "data.loc[(data['if_contact_prev']==0) & (data['Previous']>0), 'if_contact_no_camp'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rezultat poprzedniej kampanii\n",
    "data = pd.concat([data, pd.get_dummies(data['Poutcome'])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart(feature):\n",
    "    accepted = data[data['Target'] == 1][feature].value_counts()\n",
    "    declined = data[data['Target'] == 0][feature].value_counts()\n",
    "    df = pd.DataFrame([accepted, declined])\n",
    "    df.index = ['Accepted', 'Declined']\n",
    "\n",
    "    df.plot(kind='bar', stacked='True', figsize=(10, 10))\n",
    "    plt.title(feature)\n",
    "    plt.savefig('Diagrams/' + feature + \"_Diagram.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sns_plot(feature, max=0, min=0):\n",
    "    facet = sns.FacetGrid(data, hue=\"Target\", aspect=4)\n",
    "    facet.map(sns.kdeplot, feature, shade=True)\n",
    "    facet.set(xlim=(0, data[feature].max()))\n",
    "    facet.add_legend()\n",
    "    if max == 0:\n",
    "        max = data[feature].max()\n",
    "    if min == 0:\n",
    "        min = data[feature].min()\n",
    "    plt.xlim(min, max)\n",
    "\n",
    "    plt.savefig('Diagrams/' + feature + \"_Diagram.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot('Age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve(model,filename,y_train, y_test, model_name):\n",
    "\n",
    "    # Train data\n",
    "    pred_prob_tr = model.predict_proba(train_test_data[0])\n",
    "    preds_tr = pred_prob_tr[:, 1]\n",
    "    fpr_tr, tpr_tr, treshold_tr = metrics.roc_curve(y_train, preds_tr)\n",
    "    roc_auc_tr = metrics.auc(fpr_tr, tpr_tr)\n",
    "\n",
    "    # Test data\n",
    "    pred_prob = model.predict_proba(train_test_data[1])\n",
    "    preds = pred_prob[:,1]\n",
    "    fpr, tpr, treshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Test Data (AUC =%0.2f)' % roc_auc)\n",
    "    plt.plot(fpr_tr, tpr_tr, label='Train Data (AUC=%0.2f)'%roc_auc_tr)\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic Curve {model_name}')\n",
    "    plt.savefig(f'Diagrams/{filename}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grupowanie po wieku\n",
    "# for dataset in train_test_data:\n",
    "#     dataset.loc[dataset['Age']<30, 'Age'] = 0,\n",
    "#     dataset.loc[(dataset['Age']>=30) & (dataset['Age']<60),'Age'] = 1,\n",
    "#     dataset.loc[dataset['Age']>=60, 'Age']=2\n",
    "\n",
    "print(data['Age'].value_counts())\n",
    "# tworzenie wykresów dla zmiennych kategorycznych\n",
    "# for col in kolumny_kategoryczne:\n",
    "#     bar_chart(col)\n",
    "#\n",
    "# sns_plot('Age',2.5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kolumny print\n",
    "print(data.columns)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotowanie danych do modelowania\n",
    "data = data.drop('Duration', axis=1)\n",
    "data = data.drop('Job', axis=1)\n",
    "data = data.drop('quartile', axis=1)\n",
    "data = data.drop('Month', axis=1)\n",
    "data = data.drop('Education', axis=1)\n",
    "data = data.drop('Marital', axis=1)\n",
    "data = data.drop('Day_of_week', axis=1)\n",
    "data = data.drop('Poutcome', axis=1)\n",
    "data = data.drop('nonexistent', axis=1)\n",
    "data = data.drop('Marital_unk', axis=1)\n",
    "data = data.drop('unknown', axis=1)\n",
    "data = data.drop('Default', axis=1)\n",
    "data = data.drop('Pdays', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cole = []\n",
    "for col in data.columns:\n",
    "    cole.append(col)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=21)\n",
    "data = pd.DataFrame(imputer.fit_transform(data),columns=cole)\n",
    "data['Housing'] = round(data['Housing'])\n",
    "data['Personal_loan'] = round(data['Personal_loan'])\n",
    "print(data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacja\n",
    "def Normalize(data):\n",
    "\n",
    "    x = data.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    data = pd.DataFrame(x_scaled, columns=cole)\n",
    "    return data\n",
    "\n",
    "# Normalizacja\n",
    "data = Normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela ze wszystkimi rekordami\n",
    "data.to_csv('full_data_normalized.csv')\n",
    "\n",
    "Y = pd.DataFrame()\n",
    "X = pd.DataFrame()\n",
    "Y['Target'] = data['Target']\n",
    "print(Y)\n",
    "X = data.drop(['Target'], 1)\n",
    "print(X)\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.4, random_state=101)\n",
    "train = pd.concat([x_train, y_train], axis=1, sort=False)\n",
    "test = pd.concat([x_test, y_test], axis=1, sort=False)\n",
    "train_test_data = [train, test]\n",
    "target_train = train_test_data[0]['Target']\n",
    "target_test = train_test_data[1]['Target']\n",
    "train_test_data[0] = train_test_data[0].drop('Target', axis=1)\n",
    "train_test_data[1] = train_test_data[1].drop('Target', axis=1)\n",
    "print(train.columns)\n",
    "\n",
    "print(train_test_data[0]['euribor3m'].describe())\n",
    "\n",
    "print(train_test_data[0].shape)\n",
    "print(train_test_data[0].dtypes)\n",
    "\n",
    "\n",
    "cole = []\n",
    "for col in train_test_data[0].columns:\n",
    "    cole.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN IMPUTER\n",
    "for dataset in train_test_data:\n",
    "    print(dataset.dtypes)\n",
    "# imputer = KNNImputer(n_neighbors=21)\n",
    "# train_test_data[0] = pd.DataFrame(imputer.fit_transform(train_test_data[0]),columns=cole)\n",
    "# train_test_data[1] = pd.DataFrame( imputer.fit_transform(train_test_data[1]),columns=cole)\n",
    "# for dataset in train_test_data:\n",
    "#     dataset['Housing'] = round(dataset['Housing'])\n",
    "#     dataset['Personal_loan'] = round(dataset['Personal_loan'])\n",
    "\n",
    "print(train_test_data[0].isnull().sum(axis=0))\n",
    "print(train_test_data[1].isnull().sum(axis=0))\n",
    "train_test_data[0].to_csv('trainx.csv')\n",
    "train_test_data[1].to_csv('trainxxx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_test_data[0].columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO CSV\n",
    "train_test_data[0].to_csv('train.csv')\n",
    "train_test_data[1].to_csv('test.csv')\n",
    "# DO SAS'a\n",
    "train_sas = pd.concat([train_test_data[0], target_train], axis=1)\n",
    "train_sas.to_csv('train_sas.csv')\n",
    "test_sas = pd.concat([train_test_data[1], target_test], axis=1)\n",
    "test_sas.to_csv('test_sas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresja logistyczna\n",
    "\n",
    "grid=[ {\"C\":np.logspace(-3,3,7), \"penalty\":['l1'], 'solver':[ 'liblinear','saga']},\n",
    "       {\"C\":np.logspace(-3,3,7), \"penalty\":['l2'], 'solver':['lbfgs','newton-cg', 'sag']}]# l1 lasso l2 ridge\n",
    "# # WALIDACJA KRZYŻOWA\n",
    "# reg = LogisticRegression(max_iter= 10000)\n",
    "# reg_cv=GridSearchCV(reg,grid,cv=3, n_jobs=1)\n",
    "# reg_cv.fit(train_test_data[0], target_train)\n",
    "#\n",
    "#\n",
    "# print(\"accuracy :\",reg_cv.best_score_)\n",
    "# print(\"tuned hpyerparameters :(best parameters) \",reg_cv.best_params_)\n",
    "#\n",
    "#\n",
    "# print(reg_cv.predict(train_test_data[1]))\n",
    "# print(\"Logistic regression score: \", reg_cv.score(train_test_data[1], target_test)*100,\"%\")\n",
    "\n",
    "\n",
    "reg = LogisticRegression(C=10, penalty='l1',solver='saga',max_iter= 10000)\n",
    "reg.fit(train_test_data[0],target_train)\n",
    "print(\"Logistic regression score: \", reg.score(train_test_data[1], target_test)*100,\"%\")\n",
    "print(\"Logistic regression coefficients: \", reg.coef_)\n",
    "preds = reg.predict(train_test_data[1])\n",
    "np.savetxt('logistic_preds.csv',reg.predict_proba(train_test_data[1]),delimiter=';')\n",
    "print(\"Macierz trafien: \",confusion_matrix(target_test, preds))\n",
    "roc_curve(reg,\"ROC_REG\",target_train,target_test,\"REG\")\n",
    "skplt.metrics.plot_lift_curve(target_test,reg.predict_proba(train_test_data[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=6, max_features='auto', min_samples_split=0.1, max_leaf_nodes=16, random_state=72 )\n",
    "clf.fit(train_test_data[0], target_train)\n",
    "\n",
    "print(\"Decision tree score: \", clf.score(train_test_data[1], target_test))\n",
    "preds = clf.predict(train_test_data[1])\n",
    "np.savetxt('decision_tree_preds.csv',clf.predict_proba(train_test_data[1]),delimiter=';')\n",
    "print(\"Macierz trafien: \",confusion_matrix(target_test, preds))\n",
    "export_graphviz(clf,out_file='Diagrams/DecisionTree.dot',class_names=True, label='all',\n",
    "                      rounded=True, filled = True)\n",
    "roc_curve(clf,\"ROC_CLF\",target_train,target_test,\"CLF\")\n",
    "skplt.metrics.plot_lift_curve(target_test,clf.predict_proba(train_test_data[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K NEAREST NEIGHBOURS\n",
    "\n",
    "grid_knn = [{'n_neighbors':np.arange(2,30),'weights':['uniform','distance'], 'algorithm':['ball_tree','kd_tree','brute'],'leaf_size':[50,40,20,15],'p':[1,2]}]\n",
    "knn = KNeighborsClassifier(n_jobs=10)\n",
    "knn_cv = GridSearchCV(knn,grid_knn, cv=3)\n",
    "knn_cv.fit(train_test_data[0],target_train)\n",
    "print(\"accuracy :\",knn_cv.best_score_)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",knn_cv.best_params_)\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=50, n_jobs = 10, weights='uniform', p=1, algorithm='ball_tree', leaf_size=50)\n",
    "knn.fit(train_test_data[0], target_train)\n",
    "\n",
    "\n",
    "print(\"KNN score: \", knn.score(train_test_data[1], target_test))\n",
    "preds = knn.predict(train_test_data[1])\n",
    "np.savetxt('knn_preds.csv',knn.predict_proba(train_test_data[1]),delimiter=';')\n",
    "print(\"Macierz trafien: \",confusion_matrix(target_test, preds))\n",
    "\n",
    "roc_curve(knn,\"ROC_KNN\",target_train,target_test,\"KNN\")\n",
    "skplt.metrics.plot_lift_curve(target_test,knn.predict_proba(train_test_data[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "\n",
    "from sklearn import metrics\n",
    "fig, (ax, ax1) = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))\n",
    "\n",
    "probs = clf.predict_proba(train_test_data[1])\n",
    "preds = probs[:,1]\n",
    "fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(target_test, preds)\n",
    "roc_aucgbk = metrics.auc(fprgbk, tprgbk)\n",
    "\n",
    "ax1.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\n",
    "ax1.plot([0, 1], [0, 1],'r--')\n",
    "ax1.set_title('Receiver Operating Characteristic Decision Tree ',fontsize=10)\n",
    "ax1.set_ylabel('True Positive Rate',fontsize=20)\n",
    "ax1.set_xlabel('False Positive Rate',fontsize=15)\n",
    "ax1.legend(loc = 'lower right', prop={'size': 16})\n",
    "\n",
    "plt.subplots_adjust(wspace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
